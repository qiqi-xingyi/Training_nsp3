name: CNNbLSTM_ESM1b_finetune
save_dir: saved/nsp3_client/CNNbLSTM_ESM1b/
seed: 1234
target_devices: [0]

arch:
  type: CNNbLSTM_ESM1b
  args:
    init_n_channels: 1280
    out_channels: 32
    cnn_layers: 2
    kernel_size: [129, 257]
    padding: [64, 128]
    n_hidden: 1024
    dropout: 0.5
    lstm_layers: 2
    language_model: "../models/esm1b_t33_650M_UR50S.pt"
    ft_lm_head: true

data_loader:
  type: NSPDataLoader
  args:
    train_path: [../data/nsp2/training_data/Train_HHblits.npz]
    test_path: [../data/nsp2/training_data/CASP12_HHblits.npz, 
                ../data/nsp2/training_data/CB513_HHblits.npz, 
                ../data/nsp2/training_data/TS115_HHblits.npz]
    dataset_loader: NSPDataOnlyEncoding
    batch_size: 15
    nworkers: 2
    shuffle: true
    validation_split: 0.05

loss: secondary_structure_loss

metrics:
  metric_ss8: 0
  metric_ss3: 1

optimizer:
  type: Adam
  args:
    lr: 0.0005
    weight_decay: 0

lr_scheduler: 
  type: null

training:
  early_stop: 3
  epochs: 100
  monitor: min val_loss
  save_period: 1
  tensorboard: true
